{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30853b3",
   "metadata": {},
   "source": [
    "### Recommendation system for Immigrant users by Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d2e348",
   "metadata": {},
   "source": [
    "#### installation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b782046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy\n",
    "# !pip install pandas\n",
    "# !pip install psycopg2\n",
    "# !pip install flask\n",
    "# !pip install scikit-learn\n",
    "# help()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c744366",
   "metadata": {},
   "source": [
    "#### Data reading directly from postgres database server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f5be00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'google_id',\n",
       " 'username',\n",
       " 'password',\n",
       " 'email',\n",
       " 'phone_number',\n",
       " 'first_name',\n",
       " 'last_name',\n",
       " 'birth_date',\n",
       " 'profile_photo',\n",
       " 'gender',\n",
       " 'country_of_origin',\n",
       " 'language_preference',\n",
       " 'date_joined',\n",
       " 'last_login',\n",
       " 'street_address',\n",
       " 'city',\n",
       " 'state_province',\n",
       " 'country',\n",
       " 'postal_code',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'time_zone']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Establish a connection to the database\n",
    "engine = create_engine('postgresql://postgres:postgres@localhost:5432/homeheart_database')\n",
    "\n",
    "# Query the database directly and load data into a pandas DataFrame\n",
    "users = pd.read_sql_table('users', engine)\n",
    "professionals = pd.read_sql_table('medical_professionals', engine)\n",
    "# professionals.head()\n",
    "professionals.columns.tolist()\n",
    "users.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d3244",
   "metadata": {},
   "source": [
    "#### The recommender engine using content based filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16b6ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "def get_cosine_sim():\n",
    "    # For both users and professionals, combine the necessary features into a single string\n",
    "    # Fill NaN values with an empty string\n",
    "    users[\"language_preference\"] = users[\"language_preference\"].fillna('')\n",
    "    users[\"country_of_origin\"] = users[\"country_of_origin\"].fillna('')\n",
    "    professionals[\"language_proficiency\"] = professionals[\"language_proficiency\"].fillna('')\n",
    "    professionals[\"country_of_operation\"] = professionals[\"country_of_operation\"].fillna('')\n",
    "    professionals[\"specialization\"] = professionals[\"specialization\"].fillna('')\n",
    "\n",
    "    users[\"combined_features\"] = users[\"language_preference\"] + \" \" + users[\"country_of_origin\"]\n",
    "    professionals[\"combined_features\"] = professionals[\"language_proficiency\"] + \" \" + professionals[\"country_of_operation\"] + \" \" + professionals[\"specialization\"]\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    combined = pd.concat([users, professionals])\n",
    "\n",
    "    # Initialize a CountVectorizer (this converts the text to a matrix of token counts)\n",
    "    count = CountVectorizer()\n",
    "\n",
    "    # Fit and transform the 'combined_features' of our combined dataframe\n",
    "    count_matrix = count.fit_transform(combined['combined_features'])\n",
    "\n",
    "    # Compute the Cosine Similarity matrix based on the count_matrix.\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "    # Save your trained model\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump(cosine_sim, file)\n",
    "    \n",
    "    return cosine_sim, combined\n",
    "\n",
    "\n",
    "cosine_sim, combined = get_cosine_sim()\n",
    "\n",
    "\n",
    "\n",
    "def get_recommendations(user_id):\n",
    "    # For both users and professionals, combine the necessary features into a single string\n",
    "    users[\"combined_features\"] = users[\"language_preference\"] + \" \" + users[\"country_of_origin\"]\n",
    "    professionals[\"combined_features\"] = professionals[\"language_proficiency\"] + \" \" + professionals[\"country_of_operation\"] + \" \" + professionals[\"specialization\"]\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    combined = pd.concat([users, professionals])\n",
    "\n",
    "    # Initialize a CountVectorizer (this converts the text to a matrix of token counts)\n",
    "    count = CountVectorizer()\n",
    "\n",
    "    # Fit and transform the 'combined_features' of our combined dataframe\n",
    "    # This step will generate a matrix where each row represents a user/professional\n",
    "    # and each column represents a word in 'combined_features', the value is the count of that word\n",
    "    count_matrix = count.fit_transform(combined['combined_features'])\n",
    "\n",
    "    # Compute the Cosine Similarity matrix based on the count_matrix.\n",
    "    # Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space\n",
    "    # that measures the cosine of the angle between them.\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "    # Save your trained model\n",
    "    with open('model.pkl', 'wb') as file:\n",
    "        pickle.dump(cosine_sim, file)\n",
    "\n",
    "    # Get the index of the user who needs recommendations\n",
    "    idx = combined[combined['user_id'] == user_id].index[0]\n",
    "\n",
    "    # Get a list of cosine similarity scores for that user with all others\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the list of similarity scores in descending order\n",
    "    # Each item in sim_scores is a tuple where the first element is an index,\n",
    "    # and the second is a similarity score\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores for the 10 most similar users/professionals\n",
    "    # We are excluding the first item because it's the user itself\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Extract the user/professional indices of these similar users/professionals\n",
    "    user_prof_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar users/professionals\n",
    "    return combined['professional_id'].iloc[user_prof_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767eae7",
   "metadata": {},
   "source": [
    "#### Using Flask to GET the recommended professionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ad540eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return \"Welcome to the recommendation service!\"\n",
    "\n",
    "\n",
    "@app.route('/recommendations/<int:user_id>', methods=['GET'])\n",
    "def get_recommendations():\n",
    "    recommednations = recommend_function(user_id)\n",
    "    return jsonify(recommednations)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
